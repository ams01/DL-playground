{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference wide-resnet for cifar-10\n",
    "\n",
    "> Load the trained network and run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.5.2 (default, Nov 23 2017, 16:37:01) \n",
      "[GCC 5.4.0 20160609]\n",
      "TF version: 1.8.0\n"
     ]
    }
   ],
   "source": [
    "# load the necessary\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "print('Python version:',sys.version)\n",
    "import tensorflow as tf\n",
    "print('TF version:',tf.__version__)\n",
    "from data_utils import input_pipeline\n",
    "from colorama import Fore, Style\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./slim_model/wide_resnet\n",
      "total test data: 1024\n",
      "total test data: 2048\n",
      "total test data: 3072\n",
      "total test data: 4096\n",
      "total test data: 5120\n",
      "total test data: 6144\n",
      "total test data: 7168\n",
      "total test data: 8192\n",
      "total test data: 9216\n",
      "total test data: 10240\n"
     ]
    }
   ],
   "source": [
    "#Restore the save model\n",
    "graph = tf.Graph()\n",
    "\n",
    "# test files\n",
    "CIFAR_LOCAL_FOLDER = '/home/vijay/datasets/image/cifar-10/cifar-10-batches-py'\n",
    "test_files = sorted(glob.glob(os.path.join(CIFAR_LOCAL_FOLDER, '%s*' %'eval*.tfrecords')))\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    #Load the graph\n",
    "    saver = tf.train.import_meta_graph('./slim_model/wide_resnet.meta')\n",
    "    #Restore the weights\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./slim_model/'))\n",
    "    \n",
    "    # to get all the nodes from the graph\n",
    "    # print([var.name for var in tf.get_default_graph().as_graph_def().node])\n",
    "   \n",
    "    #Restore the feeding mechanism, output tensors\n",
    "    filenames_feed = graph.get_tensor_by_name('input:0')\n",
    "    images = graph.get_tensor_by_name('images:0')\n",
    "    labels = graph.get_tensor_by_name('labels:0')\n",
    "    pred = graph.get_tensor_by_name('pred:0')\n",
    "    is_train = graph.get_tensor_by_name('is_train:0')\n",
    "\n",
    "    # Get iterator handle from the graph \n",
    "    handle = graph.get_tensor_by_name('handle:0')\n",
    "    \n",
    "    #make a new iterator\n",
    "    dataset = input_pipeline(filenames_feed, BATCH_SIZE,  validation=True)\n",
    "    \n",
    "    testing_iterator = dataset.make_initializable_iterator()\n",
    "    \n",
    "    # Do inference with the restored variables.\n",
    "    test_handle = sess.run(testing_iterator.string_handle(), feed_dict={filenames_feed: test_files})\n",
    "    sess.run(testing_iterator.initializer, {filenames_feed: test_files})\n",
    "    count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            test_prediction, test_images, test_labels = sess.run([pred, images, labels], {is_train:False,handle:test_handle})  \n",
    "            count += BATCH_SIZE\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "        print('total test data:',  count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:      [6 9 3 9 8 7 7 1 6 5 3 1 3 1 2 7 1 8 2 0]\n",
      "Predictions: [6 9 3 9 8 7 7 1 6 5 3 1 3 1 2 7 1 8 2 0]\n"
     ]
    }
   ],
   "source": [
    "#Check few of the predictions\n",
    "print('Labels:     ', test_labels[:20])\n",
    "print('Predictions:', test_labels[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- EOF ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
